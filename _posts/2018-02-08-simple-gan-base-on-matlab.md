---
layout: article
title:  "ç®€å•GANç½‘ç»œmatlabå®žçŽ°"
date:   2018-02-08 20:44:51 +0800
categories: [blog]
tags: [matlab, gan]
mathjax: false
---

### 1 æ¦‚è¿°
æ­¤ä»£ç åœ¨`matlab`ä¸Šæ­å»ºäº†ç®€å•çš„ç”Ÿæˆå¯¹æŠ—æ€§ç½‘ç»œï¼Œç”¨æ¥ç”Ÿæˆæ‰‹å†™æ•°å­—å›¾åƒã€‚
ç½‘ç»œä¸­ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„éšè—å±‚å‡ä¸º2å±‚ï¼Œä¸”éƒ½æ˜¯å…¨è¿žæŽ¥å±‚ï¼Œæ˜¯ä¸€ä¸ªæ¯”è¾ƒç®€å•çš„ç½‘ç»œç»“æž„ã€‚ä¸»è¦ç”¨æ¥è¯´æ˜Žæ€Žä¹ˆåœ¨`matlab`ä¸Šæ­å»º`GANï¼ˆGenerative Adversarial Netï¼‰`ç½‘ç»œã€‚

#### 1.1 ç½‘ç»œæ¨¡åž‹
å¦‚å›¾1æ‰€ç¤ºï¼Œæ˜¯ç”Ÿæˆå™¨ç½‘ç»œæ¨¡åž‹ï¼Œä¸€ä¸ªè¾“å…¥å±‚ï¼Œä¸¤ä¸ªå…¨è¿žæŽ¥å±‚ã€‚è¾“å…¥çš„æ•°æ®æ˜¯`100Ã—1`çš„å™ªå£°ï¼Œè¾“å‡ºæ˜¯`784Ã—1`çš„å‘é‡ï¼Œå°†è¾“å‡ºè¿›è¡Œ`reshape`ä¹‹åŽï¼Œå°±å¯ä»¥å¾—åˆ°ä¸€å¼ `28Ã—28`çš„æ‰‹å†™æ•°å­—å›¾åƒã€‚
![å›¾1 ç”Ÿæˆå™¨](/assets/simple-gan-base-on-matlab/generator.png)
å¦‚å›¾2æ‰€ç¤ºï¼Œæ˜¯å°†ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨è¿žæŽ¥èµ·æ¥ä¹‹åŽçš„æ¨¡åž‹ã€‚è¿™é‡Œä¸»è¦æƒ³è¯´æ˜Žä¸€ç‚¹ï¼Œåœ¨è¿›è¡Œç½‘ç»œå‚æ•°æ›´æ–°çš„æ—¶å€™ï¼Œä¸ºäº†å¾—åˆ°ç”Ÿæˆå™¨å‚æ•°çš„åå¯¼æ•°ï¼Œ`bp`è¿‡ç¨‹éœ€è¦é‰´åˆ«å™¨ï¼Œå†ä¼ åˆ°ç”Ÿæˆå™¨ã€‚

åˆ°è¿™é‡Œå°±äº§ç”Ÿäº†ä¸€ä¸ªç–‘é—®ï¼šä¸æ˜¯è¯´æ›´æ–°ç”Ÿæˆå™¨çš„æ—¶å€™ï¼Œé‰´åˆ«ç½‘ç»œçš„å‚æ•°éœ€è¦å›ºå®šä½ä¸å˜å—ï¼Œå¦‚æžœbpè¿‡ç¨‹éœ€è¦ç»è¿‡é‰´åˆ«ç½‘ç»œï¼Œé‚£åº”è¯¥æ€Žä¹ˆä¿æŒé‰´åˆ«ç½‘ç»œçš„å‚æ•°ä¸å˜å‘¢ï¼Ÿ
å…¶å®ž`bp`çš„æ—¶å€™ï¼Œåªæ˜¯ç®—å‡ºæ¥äº†å„ä¸ªç½‘ç»œå±‚å‚æ•°å¯¹äºŽ`loss`çš„åå¯¼æ•°ï¼Œåœ¨æ±‚ç”Ÿæˆå™¨çš„å‚æ•°çš„åå¯¼æ•°çš„æ—¶å€™ï¼Œé‰´åˆ«ç½‘ç»œçš„å‚æ•°çš„åå¯¼æ•°ä¹Ÿè¢«æ±‚å‡ºæ¥äº†ã€‚ä½†æ˜¯æ±‚å‡ºæ¥äº†åå¯¼æ•°ï¼Œä¸ä¸€å®šå°±è¦å¯¹ç½‘ç»œè¿›è¡Œæ›´æ–°ã€‚ä¹Ÿå°±æ˜¯æ±‚å‡ºæ¥äº†ç½‘ç»œ`loss`å¯¹ç”Ÿæˆå™¨å’Œé‰´åˆ«å™¨çš„åå¯¼æ•°ï¼Œä½†æ˜¯åªä½¿ç”¨åˆ°äº†ç”Ÿæˆå™¨çš„åå¯¼æ•°æ¥æ›´æ–°ç”Ÿæˆå™¨ã€‚
![å›¾2 å°†generatorå’Œdiscriminatorçœ‹æˆä¸€ä¸ªæ•´ä½“](/assets/simple-gan-base-on-matlab/generator-and-discriminator.png)


#### 1.2 More
* è¿™ä¸ªæ˜¯æˆ‘å†™çš„ã€åœ¨`matlab`ä¸Šå®žçŽ°`GAN`ç½‘ç»œçš„å¦å¤–ä¸€ä»½ä»£ç ï¼Œé‡Œé¢çš„ç½‘ç»œæ¨¡åž‹ä½¿ç”¨åˆ°äº†å·ç§¯ã€åå·ç§¯ç­‰ã€‚
  
  [GAN ç½‘ç»œmatlabå®žçŽ°]({% post_url 2018-06-01-gan-base-on-matlab %})
  
* åœ¨`matlab`å¹³å°ä¸Šï¼Œä½¿ç”¨`MatConvNet`æ­å»º`GAN`ç½‘ç»œçš„ä¾‹å­

  [ä½¿ç”¨MatConvNetæ­å»ºGANç½‘ç»œ]({% post_url 2018-08-27-gan-base-on-matconvnet %})

* mnist_uint8.mat [ä¸‹è½½åœ°å€](https://github.com/rasmusbergpalm/DeepLearnToolbox/tree/master/data)

### 2 å®žä¾‹
#### 2.1 å®žä¾‹1
  ðŸ˜›ðŸ˜œðŸ˜ä»£ç åœ¨`github`ï¼š[gan_adam.m](https://github.com/jonzhaocn/Simple-GAN-Base-on-Matlab/blob/master/gan_adam.m)
  è¿™é‡Œä½¿ç”¨ä¸Šé¢æåˆ°çš„ç½‘ç»œç»“æž„æ¥ç”Ÿæˆæ‰‹å†™æ•°å­—å›¾ç‰‡ï¼Œä½¿ç”¨åˆ°äº†`Adam`ç®—æ³•ä½œä¸ºä¼˜åŒ–å™¨æ¥æ›´æ–°`GAN`ç½‘ç»œã€‚

```matlab
clear;
clc;
% -----------åŠ è½½æ•°æ®
load('mnist_uint8', 'train_x');
train_x = double(reshape(train_x, 60000, 28, 28))/255;
train_x = permute(train_x,[1,3,2]);
train_x = reshape(train_x, 60000, 784);
% -----------------å®šä¹‰æ¨¡åž‹
generator = nnsetup([100, 512, 784]);
discriminator = nnsetup([784, 512, 1]);
% -----------å¼€å§‹è®­ç»ƒ
batch_size = 60;
epoch = 100;
images_num = 60000;
batch_num = ceil(images_num / batch_size);
learning_rate = 0.001;
for e=1:epoch
    kk = randperm(images_num);
    for t=1:batch_num
        % å‡†å¤‡æ•°æ®
        images_real = train_x(kk((t - 1) * batch_size + 1:t * batch_size), :, :);
        noise = unifrnd(-1, 1, batch_size, 100);
        % å¼€å§‹è®­ç»ƒ
        % -----------æ›´æ–°generatorï¼Œå›ºå®šdiscriminator
        generator = nnff(generator, noise);
        images_fake = generator.layers{generator.layers_count}.a;
        discriminator = nnff(discriminator, images_fake);
        logits_fake = discriminator.layers{discriminator.layers_count}.z;
        discriminator = nnbp_d(discriminator, logits_fake, ones(batch_size, 1));
        generator = nnbp_g(generator, discriminator);
        generator = nnapplygrade(generator, learning_rate);
        % -----------æ›´æ–°discriminatorï¼Œå›ºå®šgenerator
        generator = nnff(generator, noise);
        images_fake = generator.layers{generator.layers_count}.a;
        images = [images_fake;images_real];
        discriminator = nnff(discriminator, images);
        logits = discriminator.layers{discriminator.layers_count}.z;
        labels = [zeros(batch_size,1);ones(batch_size,1)];
        discriminator = nnbp_d(discriminator, logits, labels);
        discriminator = nnapplygrade(discriminator, learning_rate);
        % ----------------è¾“å‡ºloss
        if t == batch_num
            c_loss = sigmoid_cross_entropy(logits(1:batch_size), ones(batch_size, 1));
            d_loss = sigmoid_cross_entropy(logits, labels);
            fprintf('c_loss:"%f",d_loss:"%f"\n',c_loss, d_loss);
        end
        if t == batch_num
            path = ['./pics/epoch_',int2str(e),'_t_',int2str(t),'.png'];
            save_images(images_fake, [4, 4], path);
            fprintf('save_sample:%s\n', path);
        end
    end
end
% sigmoidæ¿€æ´»å‡½æ•°
function output = sigmoid(x)
    output =1./(1+exp(-x));
end
% relu
function output = relu(x)
    output = max(x, 0);
end
% reluå¯¹xçš„å¯¼æ•°
function output = delta_relu(x)
    output = max(x,0);
    output(output>0) = 1;
end
% äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œæ­¤å¤„çš„logitsæ˜¯æœªç»è¿‡sigmoidæ¿€æ´»çš„
% https://www.tensorflow.org/api_docs/python/tf/nn/sigmoid_cross_entropy_with_logits
function result = sigmoid_cross_entropy(logits, labels)
    result = max(logits, 0) - logits .* labels + log(1 + exp(-abs(logits)));
    result = mean(result);
end
% sigmoid_cross_entropyå¯¹logitsçš„å¯¼æ•°ï¼Œæ­¤å¤„çš„logitsæ˜¯æœªç»è¿‡sigmoidæ¿€æ´»çš„
function result = delta_sigmoid_cross_entropy(logits, labels)
    temp1 = max(logits, 0);
    temp1(temp1>0) = 1;
    temp2 = logits;
    temp2(temp2>0) = -1;
    temp2(temp2<0) = 1;
    result = temp1 - labels + exp(-abs(logits))./(1+exp(-abs(logits))) .* temp2;
end
% æ ¹æ®æ‰€ç»™çš„ç»“æž„å»ºç«‹ç½‘ç»œ
function nn = nnsetup(architecture)
    nn.architecture   = architecture;
    nn.layers_count = numel(nn.architecture);
    % t,beta1,beta2,epsilon,nn.layers{i}.w_m,nn.layers{i}.w_v,nn.layers{i}.b_m,nn.layers{i}.b_væ˜¯åº”ç”¨adamç®—æ³•æ›´æ–°ç½‘ç»œæ‰€éœ€çš„å˜é‡
    nn.t = 0;
    nn.beta1 = 0.9;
    nn.beta2 = 0.999;
    nn.epsilon = 10^(-8);
    % å‡è®¾ç»“æž„ä¸º[100, 512, 784]ï¼Œåˆ™æœ‰3å±‚ï¼Œè¾“å…¥å±‚100ï¼Œä¸¤ä¸ªéšè—å±‚ï¼š100*512ï¼Œ512*784, è¾“å‡ºä¸ºæœ€åŽä¸€å±‚çš„aå€¼ï¼ˆæ¿€æ´»å€¼ï¼‰
    for i = 2 : nn.layers_count   
        nn.layers{i}.w = normrnd(0, 0.02, nn.architecture(i-1), nn.architecture(i));
        nn.layers{i}.b = normrnd(0, 0.02, 1, nn.architecture(i));
        nn.layers{i}.w_m = 0;
        nn.layers{i}.w_v = 0;
        nn.layers{i}.b_m = 0;
        nn.layers{i}.b_v = 0;
    end
end
% å‰å‘ä¼ é€’
function nn = nnff(nn, x)
    nn.layers{1}.a = x;
    for i = 2 : nn.layers_count
        input = nn.layers{i-1}.a;
        w = nn.layers{i}.w;
        b = nn.layers{i}.b;
        nn.layers{i}.z = input*w + repmat(b, size(input, 1), 1);
        if i ~= nn.layers_count
            nn.layers{i}.a = relu(nn.layers{i}.z);
        else
            nn.layers{i}.a = sigmoid(nn.layers{i}.z);
        end
    end
end
% discriminatorçš„bpï¼Œä¸‹é¢çš„bpæ¶‰åŠåˆ°å¯¹å„ä¸ªå‚æ•°çš„æ±‚å¯¼
% å¦‚æžœæ›´æ”¹ç½‘ç»œç»“æž„ï¼ˆæ¿€æ´»å‡½æ•°ç­‰ï¼‰åˆ™æ¶‰åŠåˆ°bpçš„æ›´æ”¹ï¼Œæ›´æ”¹weightsï¼Œbiasesçš„ä¸ªæ•°åˆ™ä¸éœ€è¦æ›´æ”¹bp
% ä¸ºäº†æ›´æ–°w,bï¼Œå°±æ˜¯è¦æ±‚æœ€ç»ˆçš„losså¯¹wï¼Œbçš„åå¯¼æ•°ï¼Œæ®‹å·®å°±æ˜¯åœ¨æ±‚wï¼Œbåå¯¼æ•°çš„ä¸­é—´è®¡ç®—è¿‡ç¨‹çš„ç»“æžœ
function nn = nnbp_d(nn, y_h, y)
    % dè¡¨ç¤ºæ®‹å·®ï¼Œæ®‹å·®å°±æ˜¯æœ€ç»ˆçš„losså¯¹å„å±‚æœªæ¿€æ´»å€¼ï¼ˆzï¼‰çš„åå¯¼ï¼Œåå¯¼æ•°çš„è®¡ç®—éœ€è¦é‡‡ç”¨é“¾å¼æ±‚å¯¼æ³•åˆ™-è‡ªå·±æ‰‹åŠ¨æŽ¨å‡ºæ¥
    n = nn.layers_count;
    % æœ€åŽä¸€å±‚çš„æ®‹å·®
    nn.layers{n}.d = delta_sigmoid_cross_entropy(y_h, y);
    for i = n-1:-1:2
        d = nn.layers{i+1}.d;
        w = nn.layers{i+1}.w;
        z = nn.layers{i}.z;
        % æ¯ä¸€å±‚çš„æ®‹å·®æ˜¯å¯¹æ¯ä¸€å±‚çš„æœªæ¿€æ´»å€¼æ±‚åå¯¼æ•°ï¼Œæ‰€ä»¥æ˜¯åŽä¸€å±‚çš„æ®‹å·®ä¹˜ä¸Šw,å†ä¹˜ä¸Šå¯¹æ¿€æ´»å€¼å¯¹æœªæ¿€æ´»å€¼çš„åå¯¼æ•°
        nn.layers{i}.d = d*w' .* delta_relu(z);    
    end
    % æ±‚å‡ºå„å±‚çš„æ®‹å·®ä¹‹åŽï¼Œå°±å¯ä»¥æ ¹æ®æ®‹å·®æ±‚å‡ºæœ€ç»ˆlosså¯¹weightså’Œbiasesçš„åå¯¼æ•°
    for i = 2:n
        d = nn.layers{i}.d;
        a = nn.layers{i-1}.a;
        % dwæ˜¯å¯¹æ¯å±‚çš„weightsè¿›è¡Œåå¯¼æ•°çš„æ±‚è§£
        nn.layers{i}.dw = a'*d / size(d, 1);
        nn.layers{i}.db = mean(d, 1);
    end
end
% generatorçš„bp
function g_net = nnbp_g(g_net, d_net)
    n = g_net.layers_count;
    a = g_net.layers{n}.a;
    % generatorçš„lossæ˜¯ç”±label_fakeå¾—åˆ°çš„ï¼Œ(images_fakeè¿‡discriminatorå¾—åˆ°label_fake)
    % å¯¹gè¿›è¡Œbpçš„æ—¶å€™ï¼Œå¯ä»¥å°†gå’Œdçœ‹æˆæ˜¯ä¸€ä¸ªæ•´ä½“
    % gæœ€åŽä¸€å±‚çš„æ®‹å·®ç­‰äºŽdç¬¬2å±‚çš„æ®‹å·®ä¹˜ä¸Š(a .* (a_o))
    g_net.layers{n}.d = d_net.layers{2}.d * d_net.layers{2}.w' .* (a .* (1-a));
    for i = n-1:-1:2
        d = g_net.layers{i+1}.d;
        w = g_net.layers{i+1}.w;
        z = g_net.layers{i}.z;
        % æ¯ä¸€å±‚çš„æ®‹å·®æ˜¯å¯¹æ¯ä¸€å±‚çš„æœªæ¿€æ´»å€¼æ±‚åå¯¼æ•°ï¼Œæ‰€ä»¥æ˜¯åŽä¸€å±‚çš„æ®‹å·®ä¹˜ä¸Šw,å†ä¹˜ä¸Šå¯¹æ¿€æ´»å€¼å¯¹æœªæ¿€æ´»å€¼çš„åå¯¼æ•°
        g_net.layers{i}.d = d*w' .* delta_relu(z);    
    end
    % æ±‚å‡ºå„å±‚çš„æ®‹å·®ä¹‹åŽï¼Œå°±å¯ä»¥æ ¹æ®æ®‹å·®æ±‚å‡ºæœ€ç»ˆlosså¯¹weightså’Œbiasesçš„åå¯¼æ•°
    for i = 2:n
        d = g_net.layers{i}.d;
        a = g_net.layers{i-1}.a;
        % dwæ˜¯å¯¹æ¯å±‚çš„weightsè¿›è¡Œåå¯¼æ•°çš„æ±‚è§£
        g_net.layers{i}.dw = a'*d / size(d, 1);
        g_net.layers{i}.db = mean(d, 1);
    end
end
% åº”ç”¨æ¢¯åº¦
% ä½¿ç”¨adamç®—æ³•æ›´æ–°å˜é‡ï¼Œå¯ä»¥å‚è€ƒï¼š
% https://www.tensorflow.org/api_docs/python/tf/train/AdamOptimizer
function nn = nnapplygrade(nn, learning_rate)
    n = nn.layers_count;
    nn.t = nn.t+1;
    beta1 = nn.beta1;
    beta2 = nn.beta2;
    lr = learning_rate * sqrt(1-nn.beta2^nn.t) / (1-nn.beta1^nn.t);
    for i = 2:n
        dw = nn.layers{i}.dw;
        db = nn.layers{i}.db;
        % ä¸‹é¢çš„6è¡Œä»£ç æ˜¯ä½¿ç”¨adamæ›´æ–°weightsä¸Žbiases
        nn.layers{i}.w_m = beta1 * nn.layers{i}.w_m + (1-beta1) * dw;
        nn.layers{i}.w_v = beta2 * nn.layers{i}.w_v + (1-beta2) * (dw.*dw);
        nn.layers{i}.w = nn.layers{i}.w - lr * nn.layers{i}.w_m ./ (sqrt(nn.layers{i}.w_v) + nn.epsilon);
        nn.layers{i}.b_m = beta1 * nn.layers{i}.b_m + (1-beta1) * db;
        nn.layers{i}.b_v = beta2 * nn.layers{i}.b_v + (1-beta2) * (db.*db);
        nn.layers{i}.b = nn.layers{i}.b - lr * nn.layers{i}.b_m ./ (sqrt(nn.layers{i}.b_v) + nn.epsilon); 
    end
end
% ä¿å­˜å›¾ç‰‡ï¼Œä¾¿äºŽè§‚å¯Ÿgeneratorç”Ÿæˆçš„images_fake
function save_images(images, count, path)
    n = size(images, 1);
    row = count(1);
    col = count(2);
    I = zeros(row*28, col*28);
    for i = 1:row
        for j = 1:col
            r_s = (i-1)*28+1;
            c_s = (j-1)*28+1;
            index = (i-1)*col + j;
            pic = reshape(images(index, :), 28, 28);
            I(r_s:r_s+27, c_s:c_s+27) = pic;
        end
    end
    imwrite(I, path);
end
```
ç»“æžœ
![epoch_5_t_1000.png](/assets/simple-gan-base-on-matlab/example1-result1.png)
![epoch_13_t_1000.png](/assets/simple-gan-base-on-matlab/example1-result2.png)

#### 2.2 å®žä¾‹2ï¼ŒMini-batch Gradient Descent
ðŸ˜›ðŸ˜œðŸ˜ä»£ç åœ¨`github`ï¼š[gan_mbgd.m](https://github.com/jonzhaocn/Simple-GAN-Base-on-Matlab/blob/master/gan_mbgd.m)

è¿™é‡Œä½¿ç”¨çš„ç½‘ç»œç»“æž„ä¸Žå®žä¾‹1çš„ä¸€æ ·ï¼Œåªæ˜¯æ¢äº†ä¸€ç§ä¼˜åŒ–å™¨ã€‚ä½¿ç”¨Mini-batch Gradient Descentç®—æ³•æ›´æ–°GANç½‘ç»œï¼Œä¸‹é¢æ˜¯éƒ¨åˆ†ä»£ç ã€‚
```matlab
% åº”ç”¨æ¢¯åº¦
function nn = nnapplygrade(nn, learning_rate)
    n = nn.layers_count;
    for i = 2:n
        dw = nn.layers{i}.dw;
        db = nn.layers{i}.db;
        nn.layers{i}.w = nn.layers{i}.w - learning_rate * dw;
        nn.layers{i}.b = nn.layers{i}.b - learning_rate * db;
    end
end
```
ç»“æžœï¼š
![epoch_11_t_1000.png](/assets/simple-gan-base-on-matlab/example2-result1.png)

![epoch_13_t_1000.png](/assets/simple-gan-base-on-matlab/example2-result2.png)

